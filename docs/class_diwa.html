<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Diwa: Diwa Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Diwa
   </div>
   <div id="projectbrief">Lightweight implementation of Artificial Neural Network for resource-constrained environments</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('class_diwa.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="class_diwa-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">Diwa Class Reference<span class="mlabels"><span class="mlabel">final</span></span></div></div>
</div><!--header-->
<div class="contents">

<p>Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.  
 <a href="class_diwa.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="diwa_8h_source.html">diwa.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a9f098c6b685502e23796e82de2897d0e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a9f098c6b685502e23796e82de2897d0e">Diwa</a> ()</td></tr>
<tr class="memdesc:a9f098c6b685502e23796e82de2897d0e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default constructor for the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> class.  <br /></td></tr>
<tr class="separator:a9f098c6b685502e23796e82de2897d0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99a875efca6521c42d0a167b6d6d8d93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a99a875efca6521c42d0a167b6d6d8d93">~Diwa</a> ()</td></tr>
<tr class="memdesc:a99a875efca6521c42d0a167b6d6d8d93"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor for the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> class.  <br /></td></tr>
<tr class="separator:a99a875efca6521c42d0a167b6d6d8d93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9647345843529f26c7ec3959697d73e0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="diwa_8h.html#a669df21efbcbba971edbc5d4e091061a">DiwaError</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a9647345843529f26c7ec3959697d73e0">initialize</a> (int inputNeurons, int hiddenLayers, int hiddenNeurons, int outputNeurons, bool randomizeWeights=true)</td></tr>
<tr class="memdesc:a9647345843529f26c7ec3959697d73e0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> neural network with specified parameters.  <br /></td></tr>
<tr class="separator:a9647345843529f26c7ec3959697d73e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0677924dfd094ccc8f295feb896d96a7"><td class="memItemLeft" align="right" valign="top">double *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a0677924dfd094ccc8f295feb896d96a7">inference</a> (double *inputs)</td></tr>
<tr class="memdesc:a0677924dfd094ccc8f295feb896d96a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform inference on the neural network.  <br /></td></tr>
<tr class="separator:a0677924dfd094ccc8f295feb896d96a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a513dc40d5b18567013ea84185c91089b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a513dc40d5b18567013ea84185c91089b">train</a> (double learningRate, double *inputNeurons, double *outputNeurons)</td></tr>
<tr class="memdesc:a513dc40d5b18567013ea84185c91089b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the neural network using backpropagation.  <br /></td></tr>
<tr class="separator:a513dc40d5b18567013ea84185c91089b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a371512f843adf6d0ea6c70581224d311"><td class="memItemLeft" align="right" valign="top"><a class="el" href="diwa_8h.html#a669df21efbcbba971edbc5d4e091061a">DiwaError</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a371512f843adf6d0ea6c70581224d311">loadFromFile</a> (std::ifstream &amp;annFile)</td></tr>
<tr class="memdesc:a371512f843adf6d0ea6c70581224d311"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load neural network model from file in non-Arduino environment.  <br /></td></tr>
<tr class="separator:a371512f843adf6d0ea6c70581224d311"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafbb6e742fabf31fe09fa9d3158e558b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="diwa_8h.html#a669df21efbcbba971edbc5d4e091061a">DiwaError</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#aafbb6e742fabf31fe09fa9d3158e558b">saveToFile</a> (std::ofstream &amp;annFile)</td></tr>
<tr class="memdesc:aafbb6e742fabf31fe09fa9d3158e558b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Save neural network model to file in non-Arduino environment.  <br /></td></tr>
<tr class="separator:aafbb6e742fabf31fe09fa9d3158e558b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22d9a6ed4e81f2f9d6b6845f0d076866"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a22d9a6ed4e81f2f9d6b6845f0d076866">calculateAccuracy</a> (double *testInput, double *testExpectedOutput, int epoch)</td></tr>
<tr class="memdesc:a22d9a6ed4e81f2f9d6b6845f0d076866"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the accuracy of the neural network on test data.  <br /></td></tr>
<tr class="separator:a22d9a6ed4e81f2f9d6b6845f0d076866"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9334d8e482d97c52ddfe7137257b2f7c"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a9334d8e482d97c52ddfe7137257b2f7c">calculateLoss</a> (double *testInput, double *testExpectedOutput, int epoch)</td></tr>
<tr class="memdesc:a9334d8e482d97c52ddfe7137257b2f7c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the loss of the neural network on test data.  <br /></td></tr>
<tr class="separator:a9334d8e482d97c52ddfe7137257b2f7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8474411623a6e505b6472ed08cf442d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#ab8474411623a6e505b6472ed08cf442d">setActivationFunction</a> (<a class="el" href="diwa__activations_8h.html#aafa05ac5c062e638690c6449f8e1d76a">diwa_activation</a> activation)</td></tr>
<tr class="memdesc:ab8474411623a6e505b6472ed08cf442d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the activation function for the neural network.  <br /></td></tr>
<tr class="separator:ab8474411623a6e505b6472ed08cf442d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a410c77ad562f6e49f9d79c4fde37ac3d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="diwa__activations_8h.html#aafa05ac5c062e638690c6449f8e1d76a">diwa_activation</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_diwa.html#a410c77ad562f6e49f9d79c4fde37ac3d">getActivationFunction</a> () const</td></tr>
<tr class="memdesc:a410c77ad562f6e49f9d79c4fde37ac3d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves the current activation function used by the neural network.  <br /></td></tr>
<tr class="separator:a410c77ad562f6e49f9d79c4fde37ac3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers. </p>
<p>The <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> library is designed to provide a simple yet effective implementation of a Feedforward Artificial Neural Network (ANN) for resource-constrained microcontroller environments such as ESP8266, ESP32, and similar development boards.</p>
<dl class="section note"><dt>Note</dt><dd>This library is primarily intended for lightweight applications. For more intricate tasks, consider using advanced machine learning libraries on more powerful platforms. </dd></dl>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a9f098c6b685502e23796e82de2897d0e" name="a9f098c6b685502e23796e82de2897d0e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9f098c6b685502e23796e82de2897d0e">&#9670;&#160;</a></span>Diwa()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Diwa::Diwa </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Default constructor for the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> class. </p>
<p>This constructor initializes a new instance of the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> class. It sets up the neural network with default value 0 on parameters. </p>

</div>
</div>
<a id="a99a875efca6521c42d0a167b6d6d8d93" name="a99a875efca6521c42d0a167b6d6d8d93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99a875efca6521c42d0a167b6d6d8d93">&#9670;&#160;</a></span>~Diwa()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Diwa::~Diwa </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destructor for the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> class. </p>
<p>This destructor releases resources associated with the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> object upon its destruction. It ensures proper cleanup to prevent memory leaks. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a22d9a6ed4e81f2f9d6b6845f0d076866" name="a22d9a6ed4e81f2f9d6b6845f0d076866"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22d9a6ed4e81f2f9d6b6845f0d076866">&#9670;&#160;</a></span>calculateAccuracy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Diwa::calculateAccuracy </td>
          <td>(</td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>testInput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>testExpectedOutput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>epoch</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculates the accuracy of the neural network on test data. </p>
<p>This function calculates the accuracy of the neural network on a given set of test data. It compares the inferred output with the expected output for each test sample and calculates the percentage of correct inferences.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">testInput</td><td>Pointer to the input values of the test data. </td></tr>
    <tr><td class="paramname">testExpectedOutput</td><td>Pointer to the expected output values of the test data. </td></tr>
    <tr><td class="paramname">epoch</td><td>Total number of test samples in the test data.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The accuracy of the neural network on the test data as a percentage. </dd></dl>

</div>
</div>
<a id="a9334d8e482d97c52ddfe7137257b2f7c" name="a9334d8e482d97c52ddfe7137257b2f7c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9334d8e482d97c52ddfe7137257b2f7c">&#9670;&#160;</a></span>calculateLoss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Diwa::calculateLoss </td>
          <td>(</td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>testInput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>testExpectedOutput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>epoch</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculates the loss of the neural network on test data. </p>
<p>This function calculates the loss of the neural network on a given set of test data. It computes the percentage of test samples for which the inferred output does not match the expected output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">testInput</td><td>Pointer to the input values of the test data. </td></tr>
    <tr><td class="paramname">testExpectedOutput</td><td>Pointer to the expected output values of the test data. </td></tr>
    <tr><td class="paramname">epoch</td><td>Total number of test samples in the test data.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The loss of the neural network on the test data as a percentage. </dd></dl>

</div>
</div>
<a id="a410c77ad562f6e49f9d79c4fde37ac3d" name="a410c77ad562f6e49f9d79c4fde37ac3d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a410c77ad562f6e49f9d79c4fde37ac3d">&#9670;&#160;</a></span>getActivationFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="diwa__activations_8h.html#aafa05ac5c062e638690c6449f8e1d76a">diwa_activation</a> Diwa::getActivationFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Retrieves the current activation function used by the neural network. </p>
<p>This method returns the activation function currently set for the neurons in the neural network. It allows the user to query the current activation function being used for inference and training purposes. The activation function determines the output of a neuron based on its input. Different activation functions can be used depending on the nature of the problem being solved and the characteristics of the dataset. Common activation functions include sigmoid, ReLU, and tanh.</p>
<dl class="section return"><dt>Returns</dt><dd>The activation function currently set for the neural network. </dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="class_diwa.html#ab8474411623a6e505b6472ed08cf442d" title="Sets the activation function for the neural network.">Diwa::setActivationFunction()</a> </dd></dl>

</div>
</div>
<a id="a0677924dfd094ccc8f295feb896d96a7" name="a0677924dfd094ccc8f295feb896d96a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0677924dfd094ccc8f295feb896d96a7">&#9670;&#160;</a></span>inference()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double * Diwa::inference </td>
          <td>(</td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>inputs</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Perform inference on the neural network. </p>
<p>Given an array of input values, this method computes and returns an array of output values through the neural network.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>Array of input values for the neural network. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Array of output values after inference. </dd></dl>

</div>
</div>
<a id="a9647345843529f26c7ec3959697d73e0" name="a9647345843529f26c7ec3959697d73e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9647345843529f26c7ec3959697d73e0">&#9670;&#160;</a></span>initialize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="diwa_8h.html#a669df21efbcbba971edbc5d4e091061a">DiwaError</a> Diwa::initialize </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>inputNeurons</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hiddenLayers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hiddenNeurons</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>outputNeurons</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>randomizeWeights</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initializes the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> neural network with specified parameters. </p>
<p>This method initializes the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> neural network with the given parameters, including the number of input neurons, hidden layers, hidden neurons per layer, and output neurons. Additionally, it allows the option to randomize the weights in the network if desired.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputNeurons</td><td>Number of input neurons in the neural network. </td></tr>
    <tr><td class="paramname">hiddenLayers</td><td>Number of hidden layers in the neural network. </td></tr>
    <tr><td class="paramname">hiddenNeurons</td><td>Number of neurons in each hidden layer. </td></tr>
    <tr><td class="paramname">outputNeurons</td><td>Number of output neurons in the neural network. </td></tr>
    <tr><td class="paramname">randomizeWeights</td><td>Flag indicating whether to randomize weights in the network (default is true).</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>DiwaError indicating the initialization status. </dd></dl>

</div>
</div>
<a id="a371512f843adf6d0ea6c70581224d311" name="a371512f843adf6d0ea6c70581224d311"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a371512f843adf6d0ea6c70581224d311">&#9670;&#160;</a></span>loadFromFile()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="diwa_8h.html#a669df21efbcbba971edbc5d4e091061a">DiwaError</a> Diwa::loadFromFile </td>
          <td>(</td>
          <td class="paramtype">std::ifstream &amp;&#160;</td>
          <td class="paramname"><em>annFile</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load neural network model from file in non-Arduino environment. </p>
<p>This method loads a previously saved neural network model from the specified file in a non-Arduino environment. It reads the model data from the given file stream and initializes the <a class="el" href="class_diwa.html" title="Lightweight Feedforward Artificial Neural Network (ANN) library tailored for microcontrollers.">Diwa</a> object with the loaded model parameters and weights.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">annFile</td><td>Input file stream representing the neural network model file. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>DiwaError indicating the loading status. </dd></dl>

</div>
</div>
<a id="aafbb6e742fabf31fe09fa9d3158e558b" name="aafbb6e742fabf31fe09fa9d3158e558b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aafbb6e742fabf31fe09fa9d3158e558b">&#9670;&#160;</a></span>saveToFile()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="diwa_8h.html#a669df21efbcbba971edbc5d4e091061a">DiwaError</a> Diwa::saveToFile </td>
          <td>(</td>
          <td class="paramtype">std::ofstream &amp;&#160;</td>
          <td class="paramname"><em>annFile</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Save neural network model to file in non-Arduino environment. </p>
<p>This method saves the current state of the neural network model to the specified file in a non-Arduino environment. It writes the model parameters and weights to the given file stream, facilitating storage and retrieval of the trained model.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">annFile</td><td>Output file stream representing the destination file for the model. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>DiwaError indicating the saving status. </dd></dl>

</div>
</div>
<a id="ab8474411623a6e505b6472ed08cf442d" name="ab8474411623a6e505b6472ed08cf442d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab8474411623a6e505b6472ed08cf442d">&#9670;&#160;</a></span>setActivationFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Diwa::setActivationFunction </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="diwa__activations_8h.html#aafa05ac5c062e638690c6449f8e1d76a">diwa_activation</a>&#160;</td>
          <td class="paramname"><em>activation</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the activation function for the neural network. </p>
<p>This method allows the user to set the activation function used by the neurons in the neural network. The activation function determines the output of a neuron based on its input. Different activation functions can be used depending on the nature of the problem being solved and the characteristics of the dataset. Common activation functions include sigmoid, ReLU, and tanh.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">activation</td><td>The activation function to be set for the neural network. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="class_diwa.html#a410c77ad562f6e49f9d79c4fde37ac3d" title="Retrieves the current activation function used by the neural network.">Diwa::getActivationFunction()</a> </dd></dl>

</div>
</div>
<a id="a513dc40d5b18567013ea84185c91089b" name="a513dc40d5b18567013ea84185c91089b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a513dc40d5b18567013ea84185c91089b">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Diwa::train </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learningRate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>inputNeurons</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>outputNeurons</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Train the neural network using backpropagation. </p>
<p>This method facilitates the training of the neural network by adjusting its weights based on the provided input and target output values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learningRate</td><td>Learning rate for the training process. </td></tr>
    <tr><td class="paramname">inputNeurons</td><td>Array of input values for training. </td></tr>
    <tr><td class="paramname">outputNeurons</td><td>Array of target output values for training. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/<a class="el" href="diwa_8h_source.html">diwa.h</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="nav-path" class="navpath">
    <ul>
      <li class="footer">Copyright 2024 - <a href="https://github.com/nthnn" target="_blank">Nathanne Isip</a></li>
    </ul>
</div>